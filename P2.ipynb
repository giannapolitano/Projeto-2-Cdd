{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from emoji import UNICODE_EMOJI \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_toddy = pd.read_excel('tweets_toddy_201809110116.xlsx', sheet_name = 0)\n",
    "db_toddy_teste = pd.read_excel('tweets_toddy_201809110116.xlsx', sheet_name = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "tweets_rel = []\n",
    "tweets_irrel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_lista_de_tweets(lista, local):\n",
    "    for tweet in local:\n",
    "        lista.append(tweet)\n",
    "\n",
    "def cria_lista_de_tweets_com_relevancia(lista, valor):\n",
    "    for tweet in db_toddy.Treinamento[db_toddy.Relevancia == valor]:\n",
    "        lista.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cria_lista_de_tweets(tweets, db_toddy.Treinamento)\n",
    "cria_lista_de_tweets_com_relevancia(tweets_rel, 1)\n",
    "cria_lista_de_tweets_com_relevancia(tweets_irrel, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista):\n",
    "    j = 0\n",
    "    for tweet in lista:\n",
    "        for letra in tweet:\n",
    "            if letra in UNICODE_EMOJI:\n",
    "                tweet = tweet.replace(letra,' {0} '.format(letra))\n",
    "        lista[j] = tweet.split(' ')\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "separa_palavras(tweets)\n",
    "separa_palavras(tweets_rel)\n",
    "separa_palavras(tweets_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf_list = [':','\"', \"'\", '/', '...', ',', '#', ';', '$', '!', '?', '.', '…', '\\t', '%', '(', ')', '&', '*','-', \n",
    "           '0','1','2','3','4','5','6','7','8','9']\n",
    "wtf_list2 = ['http', '@']\n",
    "\n",
    "li1 = ['vc', 'você', 'qm', '+', 's', 'n', 'não', 'alguém']\n",
    "li2 = ['voce', 'você', 'quem', 'mais', 'sim', 'nao', 'nao', 'alguem']\n",
    "\n",
    "def replace_words(lista_principal, wtf, wtf2, l1, l2):\n",
    "    for lista in lista_principal:\n",
    "        for e in wtf:\n",
    "            for palavra in lista:\n",
    "                if palavra == '':\n",
    "                    lista.remove(palavra)\n",
    "                if e in palavra:\n",
    "                    palavra2 = palavra.replace(e, '')\n",
    "                    lista.remove(palavra)\n",
    "                    lista.append(palavra2)\n",
    "        \n",
    "        for palavra in lista:\n",
    "            if 'kkk' in palavra:\n",
    "                lista.remove(palavra)\n",
    "            elif 'aaa' in palavra:\n",
    "                lista.remove(palavra)\n",
    "            elif 'gtgt' in palavra:\n",
    "                lista.remove(palavra)\n",
    "            elif '\\n' in palavra:\n",
    "                palavra2 = (palavra.replace('\\n', ' ')).split(' ')\n",
    "                lista.remove(palavra)\n",
    "                for e in palavra2:\n",
    "                    lista.append(e)\n",
    "                \n",
    "        for palavra in lista:\n",
    "            for f in wtf2:\n",
    "                if f in palavra:\n",
    "                    lista.remove(palavra)\n",
    "                    \n",
    "        for palavra in lista:\n",
    "            i = 0\n",
    "            for e in li1:\n",
    "                if palavra == e:\n",
    "                    palavra2 = palavra.replace(e, li2[0])\n",
    "                    lista.remove(palavra)\n",
    "                    lista.append(palavra2)\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_words(tweets, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_rel, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_irrel, wtf_list, wtf_list2, li1, li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_words(tweets, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_rel, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_irrel, wtf_list, wtf_list2, li1, li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pal = {}\n",
    "t_pal_rel = {}\n",
    "t_pal_irrel = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conta_palavras(lista, dic):\n",
    "    for tweet in lista:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in dic:\n",
    "                dic[palavra] = 1\n",
    "            else:\n",
    "                dic[palavra] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "conta_palavras(tweets, t_pal)\n",
    "conta_palavras(tweets_rel, t_pal_rel)\n",
    "conta_palavras(tweets_irrel, t_pal_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 4,\n",
       " '#luansantanatv': 1,\n",
       " 'B': 2,\n",
       " 'Bpersonagem': 1,\n",
       " 'a': 26,\n",
       " 'abençoar': 1,\n",
       " 'acabei': 1,\n",
       " 'acabou': 1,\n",
       " 'aceita': 12,\n",
       " 'acha': 13,\n",
       " 'achei': 3,\n",
       " 'acho': 1,\n",
       " 'achocolatado': 3,\n",
       " 'achocolotado': 1,\n",
       " 'aconteceu': 1,\n",
       " 'acredito': 1,\n",
       " 'af': 2,\n",
       " 'afeira': 1,\n",
       " 'after': 1,\n",
       " 'agora': 5,\n",
       " 'agr': 2,\n",
       " 'ah': 1,\n",
       " 'ahhhh': 1,\n",
       " 'ahsjaush': 1,\n",
       " 'ai': 3,\n",
       " 'ainda': 6,\n",
       " 'ajudou': 1,\n",
       " 'algum': 1,\n",
       " 'alguma': 1,\n",
       " 'ama': 1,\n",
       " 'american': 1,\n",
       " 'amiga': 1,\n",
       " 'amo': 7,\n",
       " 'amor': 4,\n",
       " 'amém': 1,\n",
       " 'and': 1,\n",
       " 'anos': 1,\n",
       " 'anuncia': 1,\n",
       " 'ao': 5,\n",
       " 'aou': 1,\n",
       " 'apagar': 3,\n",
       " 'apanhar': 1,\n",
       " 'apenas': 1,\n",
       " 'aposto': 1,\n",
       " 'após': 1,\n",
       " 'aq': 2,\n",
       " 'aquele': 2,\n",
       " 'aqui': 4,\n",
       " 'aquário': 1,\n",
       " 'ardendo': 1,\n",
       " 'army': 1,\n",
       " 'as': 5,\n",
       " 'assim': 2,\n",
       " 'assistir': 2,\n",
       " 'atacantes': 1,\n",
       " 'atenção': 1,\n",
       " 'atrás': 1,\n",
       " 'até': 1,\n",
       " 'avenida': 1,\n",
       " 'aí': 1,\n",
       " 'baby': 2,\n",
       " 'bacon': 1,\n",
       " 'bagunçar': 1,\n",
       " 'banana': 2,\n",
       " 'banner': 1,\n",
       " 'barato': 1,\n",
       " 'basicamente': 1,\n",
       " 'bati': 1,\n",
       " 'bb': 1,\n",
       " 'bebendo': 1,\n",
       " 'beber': 2,\n",
       " 'bem': 3,\n",
       " 'bermuda': 1,\n",
       " 'bgls': 1,\n",
       " 'biscoito': 4,\n",
       " 'bitch': 1,\n",
       " 'boa': 8,\n",
       " 'boas': 1,\n",
       " 'boi': 83,\n",
       " 'bolacha': 2,\n",
       " 'bolinhas': 1,\n",
       " 'bolo': 1,\n",
       " 'bolsonaro': 1,\n",
       " 'bom': 16,\n",
       " 'bonito': 1,\n",
       " 'bonoro': 1,\n",
       " 'borocoxo': 1,\n",
       " 'bozonaro': 1,\n",
       " 'branca': 1,\n",
       " 'branco': 1,\n",
       " 'brasil': 2,\n",
       " 'brasileiro': 1,\n",
       " 'brigadeiro': 4,\n",
       " 'busca': 1,\n",
       " 'cabeça': 1,\n",
       " 'cachorro': 1,\n",
       " 'cada': 1,\n",
       " 'cafeteria': 1,\n",
       " 'café': 6,\n",
       " 'caganeira': 1,\n",
       " 'caiu': 1,\n",
       " 'caminho': 1,\n",
       " 'candidatar': 1,\n",
       " 'cara': 4,\n",
       " 'caralho': 3,\n",
       " 'carne': 1,\n",
       " 'carreira': 1,\n",
       " 'casa': 6,\n",
       " 'casal': 1,\n",
       " 'cata': 1,\n",
       " 'causa': 1,\n",
       " 'cereal': 2,\n",
       " 'certo': 1,\n",
       " 'cerveja': 2,\n",
       " 'ces': 1,\n",
       " 'chama': 1,\n",
       " 'chamar': 2,\n",
       " 'chanyeol': 2,\n",
       " 'chega': 1,\n",
       " 'chegar': 1,\n",
       " 'chegou': 1,\n",
       " 'cheguei': 1,\n",
       " 'cheio': 1,\n",
       " 'cidade': 1,\n",
       " 'cima': 1,\n",
       " 'cinema': 1,\n",
       " 'cobertor': 1,\n",
       " 'coisa': 4,\n",
       " 'cole': 1,\n",
       " 'coloca': 1,\n",
       " 'colocaram': 1,\n",
       " 'com': 44,\n",
       " 'come': 1,\n",
       " 'comediante': 1,\n",
       " 'comem': 1,\n",
       " 'comendo': 1,\n",
       " 'comente': 1,\n",
       " 'comer': 2,\n",
       " 'comerciais': 1,\n",
       " 'começa': 2,\n",
       " 'começando': 1,\n",
       " 'comi': 2,\n",
       " 'como': 11,\n",
       " 'compara': 1,\n",
       " 'comparar': 1,\n",
       " 'completar': 1,\n",
       " 'complexo': 1,\n",
       " 'compraram': 1,\n",
       " 'comprasse': 1,\n",
       " 'comprei': 2,\n",
       " 'comprou': 2,\n",
       " 'conceitos': 1,\n",
       " 'condensado': 1,\n",
       " 'consigo': 1,\n",
       " 'contratar': 1,\n",
       " 'conversando': 2,\n",
       " 'conversar': 1,\n",
       " 'convite': 1,\n",
       " 'copao': 1,\n",
       " 'copo': 4,\n",
       " 'copos': 1,\n",
       " 'coragem': 4,\n",
       " 'corações': 1,\n",
       " 'coxinha': 1,\n",
       " 'criança': 1,\n",
       " 'crise': 1,\n",
       " 'cunhado': 1,\n",
       " 'custava': 1,\n",
       " 'cvsa': 2,\n",
       " 'cy': 1,\n",
       " 'cú': 1,\n",
       " 'd': 2,\n",
       " 'da': 15,\n",
       " 'dançando': 1,\n",
       " 'daqueles': 1,\n",
       " 'dar': 2,\n",
       " 'das': 2,\n",
       " 'daí': 1,\n",
       " 'de': 149,\n",
       " 'debaixo': 1,\n",
       " 'defeito': 1,\n",
       " 'deficiente': 1,\n",
       " 'deixa': 1,\n",
       " 'deixar': 1,\n",
       " 'depende': 1,\n",
       " 'depois': 1,\n",
       " 'derramei': 1,\n",
       " 'desde': 1,\n",
       " 'desgrama': 1,\n",
       " 'desistiu': 1,\n",
       " 'deus': 2,\n",
       " 'dia': 6,\n",
       " 'diferente': 1,\n",
       " 'dimais': 1,\n",
       " 'dinheiro': 1,\n",
       " 'direito': 1,\n",
       " 'discuta': 1,\n",
       " 'discutindo': 2,\n",
       " 'dissolve': 1,\n",
       " 'ditadura': 1,\n",
       " 'divulgar': 1,\n",
       " 'dm': 2,\n",
       " 'dms': 1,\n",
       " 'do': 32,\n",
       " 'doido': 1,\n",
       " 'dois': 3,\n",
       " 'domingo': 1,\n",
       " 'doq': 1,\n",
       " 'dormir': 2,\n",
       " 'dos': 2,\n",
       " 'duas': 1,\n",
       " 'dá': 1,\n",
       " 'dívidas': 1,\n",
       " 'dórimê': 1,\n",
       " 'e': 64,\n",
       " 'el': 1,\n",
       " 'ela': 1,\n",
       " 'elas': 1,\n",
       " 'ele': 7,\n",
       " 'em': 10,\n",
       " 'emily': 1,\n",
       " 'encontrei': 1,\n",
       " 'enfrentassem': 1,\n",
       " 'enfrentava': 1,\n",
       " 'enjoado': 1,\n",
       " 'enjoo': 1,\n",
       " 'enquanto': 2,\n",
       " 'entendo': 3,\n",
       " 'então': 1,\n",
       " 'envelhecer’': 1,\n",
       " 'episódio': 1,\n",
       " 'era': 1,\n",
       " 'errada': 1,\n",
       " 'erro': 1,\n",
       " 'ervilha': 1,\n",
       " 'escreveu': 1,\n",
       " 'essa': 3,\n",
       " 'esse': 4,\n",
       " 'esta': 1,\n",
       " 'estado': 1,\n",
       " 'estar': 1,\n",
       " 'estrela': 1,\n",
       " 'estressada': 1,\n",
       " 'estresse': 1,\n",
       " 'estudando': 1,\n",
       " 'estudar': 1,\n",
       " 'está': 2,\n",
       " 'estádio': 1,\n",
       " 'eternamente': 1,\n",
       " 'eu': 50,\n",
       " 'européia': 1,\n",
       " 'exclui': 1,\n",
       " 'existe': 1,\n",
       " 'expe': 1,\n",
       " 'fala': 11,\n",
       " 'falam': 1,\n",
       " 'falar': 5,\n",
       " 'falou': 1,\n",
       " 'falta': 1,\n",
       " 'família': 1,\n",
       " 'fase': 2,\n",
       " 'fato': 1,\n",
       " 'fatos': 1,\n",
       " 'fav': 1,\n",
       " 'faz': 3,\n",
       " 'fazendo': 2,\n",
       " 'fazer': 1,\n",
       " 'fazia': 1,\n",
       " 'faço': 1,\n",
       " 'feia': 1,\n",
       " 'feio': 1,\n",
       " 'feliz': 1,\n",
       " 'festeja': 1,\n",
       " 'ffstore': 1,\n",
       " 'fica': 3,\n",
       " 'ficar': 3,\n",
       " 'ficou': 3,\n",
       " 'filhão': 1,\n",
       " 'filme': 1,\n",
       " 'fiquei': 1,\n",
       " 'firmino': 1,\n",
       " 'fiz': 4,\n",
       " 'fizestes': 1,\n",
       " 'fofo': 1,\n",
       " 'foi': 11,\n",
       " 'fome': 1,\n",
       " 'for': 1,\n",
       " 'fora': 1,\n",
       " 'forte': 1,\n",
       " 'fosse': 2,\n",
       " 'foto': 2,\n",
       " 'frase': 1,\n",
       " 'frente': 1,\n",
       " 'freskolita': 1,\n",
       " 'friends': 1,\n",
       " 'frio': 1,\n",
       " 'fruta': 1,\n",
       " 'fui': 6,\n",
       " 'funk': 1,\n",
       " 'fácil': 3,\n",
       " 'fãs': 1,\n",
       " 'fígado': 1,\n",
       " 'gabes': 1,\n",
       " 'gaga': 1,\n",
       " 'galera': 1,\n",
       " 'ganhar': 2,\n",
       " 'garotos': 1,\n",
       " 'garrafinha': 1,\n",
       " 'gases': 1,\n",
       " 'gastar': 1,\n",
       " 'gastronômicamente': 1,\n",
       " 'gaúchos': 1,\n",
       " 'gelado': 1,\n",
       " 'gema': 1,\n",
       " 'gente': 7,\n",
       " 'gif': 1,\n",
       " 'gira': 1,\n",
       " 'golpes': 1,\n",
       " 'gost': 1,\n",
       " 'gosta': 8,\n",
       " 'gostar': 1,\n",
       " 'gostei': 1,\n",
       " 'gosto': 4,\n",
       " 'grita': 1,\n",
       " 'gritou': 1,\n",
       " 'guri': 1,\n",
       " 'hahahahahaha': 1,\n",
       " 'happyyy': 1,\n",
       " 'hard': 1,\n",
       " 'hehehehehe': 1,\n",
       " 'hj': 2,\n",
       " 'hoje': 2,\n",
       " 'horrível': 1,\n",
       " 'hrs': 1,\n",
       " 'humanidade': 1,\n",
       " 'humano': 1,\n",
       " 'há': 2,\n",
       " 'i': 1,\n",
       " 'ia': 4,\n",
       " 'ideia': 1,\n",
       " 'igual': 2,\n",
       " 'iguaria': 1,\n",
       " 'im': 1,\n",
       " 'importantes': 1,\n",
       " 'impossivel': 1,\n",
       " 'indicava': 1,\n",
       " 'infernal': 1,\n",
       " 'inferno': 1,\n",
       " 'influencers': 1,\n",
       " 'ingrid': 1,\n",
       " 'inteiro': 1,\n",
       " 'inventou': 1,\n",
       " 'invés': 3,\n",
       " 'ir': 2,\n",
       " 'iria': 1,\n",
       " 'irmã': 1,\n",
       " 'isso': 3,\n",
       " 'ja': 3,\n",
       " 'jamais': 4,\n",
       " 'jean': 1,\n",
       " 'jeito': 2,\n",
       " 'jikooka': 1,\n",
       " 'jiló': 1,\n",
       " 'jimin': 1,\n",
       " 'joga': 1,\n",
       " 'jorge': 1,\n",
       " 'jr': 1,\n",
       " 'ju': 2,\n",
       " 'juan': 1,\n",
       " 'jungkook': 1,\n",
       " 'juntasse': 1,\n",
       " 'já': 4,\n",
       " 'kakakakakak': 1,\n",
       " 'kao': 1,\n",
       " 'karina': 1,\n",
       " 'kavinsky': 1,\n",
       " 'ketchup': 1,\n",
       " 'la': 6,\n",
       " 'ladrão': 1,\n",
       " 'lady': 1,\n",
       " 'lara': 1,\n",
       " 'laricando': 1,\n",
       " 'lata': 1,\n",
       " 'lc': 1,\n",
       " 'lei': 1,\n",
       " 'leite': 20,\n",
       " 'lembrando': 1,\n",
       " 'lembrar': 1,\n",
       " 'levantar': 1,\n",
       " 'levantou': 1,\n",
       " 'licença': 1,\n",
       " 'ligado': 1,\n",
       " 'liked': 1,\n",
       " 'limonada': 1,\n",
       " 'lista': 1,\n",
       " 'litoral': 1,\n",
       " 'lixa': 1,\n",
       " 'loca': 1,\n",
       " 'logo': 1,\n",
       " 'loja': 1,\n",
       " 'losejacob': 1,\n",
       " 'luanetes': 1,\n",
       " 'luansantana': 1,\n",
       " 'lula': 2,\n",
       " 'luz': 1,\n",
       " 'lá': 2,\n",
       " 'maior': 2,\n",
       " 'maioria': 1,\n",
       " 'mais': 10,\n",
       " 'malta': 1,\n",
       " 'maluco': 1,\n",
       " 'maluquice': 1,\n",
       " 'mamão': 1,\n",
       " 'manhã': 2,\n",
       " 'mano': 7,\n",
       " 'mar': 1,\n",
       " 'maravilhoso': 1,\n",
       " 'marina': 1,\n",
       " 'marketing': 1,\n",
       " 'mas': 10,\n",
       " 'me': 10,\n",
       " 'medos': 1,\n",
       " 'melhor': 53,\n",
       " 'melhores': 2,\n",
       " 'meme': 1,\n",
       " 'memo': 1,\n",
       " 'meninas': 1,\n",
       " 'menos': 2,\n",
       " 'mentira': 1,\n",
       " 'mentiu': 1,\n",
       " 'mercado': 1,\n",
       " 'merda': 4,\n",
       " 'mesma': 1,\n",
       " 'mesmo': 3,\n",
       " 'meu': 15,\n",
       " 'meus': 2,\n",
       " 'mim': 5,\n",
       " 'mina': 1,\n",
       " 'minha': 10,\n",
       " 'miojin': 1,\n",
       " 'mirou': 1,\n",
       " 'misto': 1,\n",
       " 'misturei': 2,\n",
       " 'mole': 1,\n",
       " 'moral': 1,\n",
       " 'morava': 1,\n",
       " 'moreira': 1,\n",
       " 'morrendo': 1,\n",
       " 'morrer': 1,\n",
       " 'mortadela': 1,\n",
       " 'moída': 1,\n",
       " 'mpn': 1,\n",
       " 'msc': 1,\n",
       " 'mt': 5,\n",
       " 'mto': 1,\n",
       " 'mudar': 1,\n",
       " 'mudou': 81,\n",
       " 'muitas': 1,\n",
       " 'muito': 7,\n",
       " 'mulher': 1,\n",
       " 'mundo': 4,\n",
       " 'máquinas': 1,\n",
       " 'mãe': 4,\n",
       " 'mídia': 2,\n",
       " 'música': 1,\n",
       " 'na': 16,\n",
       " 'nada': 5,\n",
       " 'nao': 5,\n",
       " 'nariz': 1,\n",
       " 'nasce': 1,\n",
       " 'nasceu': 4,\n",
       " 'nay': 1,\n",
       " 'ne': 1,\n",
       " 'negócio': 1,\n",
       " 'neil': 1,\n",
       " 'nem': 3,\n",
       " 'nescal': 1,\n",
       " 'nescau': 84,\n",
       " 'nescautoddy': 1,\n",
       " 'nessa': 2,\n",
       " 'ngm': 1,\n",
       " 'niguem': 9,\n",
       " 'ninguém': 5,\n",
       " 'nisso': 1,\n",
       " 'nmrl': 1,\n",
       " 'no': 11,\n",
       " 'noite': 5,\n",
       " 'nojento': 1,\n",
       " 'nordestino': 1,\n",
       " 'normal': 2,\n",
       " 'nos': 2,\n",
       " 'nossa': 3,\n",
       " 'notícias': 1,\n",
       " 'nova': 1,\n",
       " 'novo': 1,\n",
       " 'nu': 1,\n",
       " 'num': 1,\n",
       " 'numa': 2,\n",
       " 'nunca': 3,\n",
       " 'nunes': 1,\n",
       " 'nãoconfioemgenteque': 14,\n",
       " 'né': 2,\n",
       " 'nós': 1,\n",
       " 'o': 123,\n",
       " 'obrigado': 1,\n",
       " 'odeia': 1,\n",
       " 'odeio': 1,\n",
       " 'odiada': 1,\n",
       " 'oficialmente': 1,\n",
       " 'olha': 2,\n",
       " 'olhares': 1,\n",
       " 'olhe': 2,\n",
       " 'onde': 1,\n",
       " 'opinião': 1,\n",
       " 'oq': 1,\n",
       " 'os': 3,\n",
       " 'otaria': 1,\n",
       " 'ou': 13,\n",
       " 'out': 1,\n",
       " 'outro': 1,\n",
       " 'outros': 1,\n",
       " 'ovo': 2,\n",
       " 'ovomaltine': 1,\n",
       " 'p': 3,\n",
       " 'paga': 1,\n",
       " 'pai': 1,\n",
       " 'para': 6,\n",
       " 'parece': 1,\n",
       " 'parte': 1,\n",
       " 'participação': 1,\n",
       " 'party': 1,\n",
       " 'passada': 1,\n",
       " 'passado': 1,\n",
       " 'passar': 1,\n",
       " 'patrocina': 1,\n",
       " 'pede': 1,\n",
       " 'pedi': 1,\n",
       " 'pediu': 2,\n",
       " 'pega': 1,\n",
       " 'pegasse': 1,\n",
       " 'pelo': 2,\n",
       " 'pensando': 1,\n",
       " 'percebi': 1,\n",
       " 'perdas': 2,\n",
       " 'perdem': 1,\n",
       " 'perdeu': 1,\n",
       " 'perguntando': 1,\n",
       " 'pergunteme': 1,\n",
       " 'pesada': 1,\n",
       " 'pessoas': 8,\n",
       " 'peter': 1,\n",
       " 'ph': 1,\n",
       " 'phodda': 1,\n",
       " 'pie': 1,\n",
       " 'pior': 1,\n",
       " 'pipow': 1,\n",
       " 'pode': 3,\n",
       " 'podem': 1,\n",
       " 'poderiam': 1,\n",
       " 'podridão': 1,\n",
       " 'pois': 1,\n",
       " 'por': 5,\n",
       " 'porem': 1,\n",
       " 'porque': 3,\n",
       " 'porém': 1,\n",
       " 'posso': 1,\n",
       " 'possível': 1,\n",
       " 'postei': 1,\n",
       " 'pote': 2,\n",
       " 'povoa': 1,\n",
       " 'pq': 6,\n",
       " 'pqp': 1,\n",
       " 'pra': 29,\n",
       " 'pranamorarcmgtemq': 1,\n",
       " 'prato': 1,\n",
       " 'precisa': 2,\n",
       " 'prefere': 10,\n",
       " 'preferem': 1,\n",
       " 'preferir': 1,\n",
       " 'prefiro': 2,\n",
       " 'preguiça': 1,\n",
       " 'pressentimento': 1,\n",
       " 'presto': 1,\n",
       " 'presunto': 1,\n",
       " 'primeiro': 1,\n",
       " 'pro': 4,\n",
       " 'prof': 1,\n",
       " 'promete': 1,\n",
       " 'propaganda': 1,\n",
       " 'proposta': 1,\n",
       " 'prova': 1,\n",
       " 'provaram': 1,\n",
       " 'própria': 1,\n",
       " 'próxima': 2,\n",
       " 'próximo': 1,\n",
       " 'pudim': 1,\n",
       " 'puro,': 1,\n",
       " 'purê': 1,\n",
       " 'pus': 1,\n",
       " 'puta': 1,\n",
       " 'pvd': 1,\n",
       " 'pão': 6,\n",
       " 'pé': 3,\n",
       " 'pó': 2,\n",
       " 'pósferiado': 1,\n",
       " 'pública': 1,\n",
       " 'q': 20,\n",
       " 'qe': 1,\n",
       " 'qnd': 1,\n",
       " 'qq': 2,\n",
       " 'qualquer': 2,\n",
       " 'quando': 3,\n",
       " 'quase': 1,\n",
       " 'que': 107,\n",
       " 'quebrando': 1,\n",
       " 'queijo': 2,\n",
       " 'quem': 17,\n",
       " 'quente': 6,\n",
       " 'quenteee': 1,\n",
       " 'quer': 1,\n",
       " 'queria': 6,\n",
       " 'quero': 3,\n",
       " 'questão': 1,\n",
       " 'que”': 1,\n",
       " 'quieto': 1,\n",
       " 'radical': 1,\n",
       " 'raffa': 1,\n",
       " 'raiva': 1,\n",
       " 'ralo': 1,\n",
       " 'reais': 1,\n",
       " 'realmente': 3,\n",
       " 'receber': 1,\n",
       " 'reclamou': 1,\n",
       " 'recusaram': 1,\n",
       " 'recíproco': 1,\n",
       " 'registrado': 1,\n",
       " 'reina': 1,\n",
       " 'relatório': 1,\n",
       " 'renan': 1,\n",
       " 'repente': 1,\n",
       " 'resto': 1,\n",
       " 'rever': 1,\n",
       " 'revoltada': 1,\n",
       " 'rimas': 1,\n",
       " 'roberto': 1,\n",
       " 'role': 1,\n",
       " 'romario': 1,\n",
       " 'rosto': 1,\n",
       " 'roubar': 1,\n",
       " 'rt': 156,\n",
       " 'ruim': 2,\n",
       " 'ryca': 1,\n",
       " 'sabe': 1,\n",
       " 'saber': 5,\n",
       " 'sabia': 3,\n",
       " 'sala': 1,\n",
       " 'salve': 1,\n",
       " 'salário': 1,\n",
       " 'saudades': 1,\n",
       " 'sc': 1,\n",
       " 'se': 23,\n",
       " 'secretário': 1,\n",
       " 'secura': 1,\n",
       " 'seguindo': 1,\n",
       " 'segunda': 2,\n",
       " 'segundadetremurasdv': 1,\n",
       " 'segundamente': 1,\n",
       " 'segurando': 1,\n",
       " 'sei': 10,\n",
       " 'seja': 1,\n",
       " 'sem': 1,\n",
       " 'semana': 1,\n",
       " 'sempre': 3,\n",
       " 'sensação': 1,\n",
       " 'sentir': 2,\n",
       " 'seokjin': 2,\n",
       " 'ser': 7,\n",
       " 'será': 2,\n",
       " 'seu': 2,\n",
       " 'seus': 2,\n",
       " 'sim': 3,\n",
       " 'simm': 1,\n",
       " 'simples': 1,\n",
       " 'situações': 1,\n",
       " 'skate': 1,\n",
       " 'smksks': 1,\n",
       " 'so': 5,\n",
       " 'sobre': 3,\n",
       " 'sogra': 1,\n",
       " 'sono': 1,\n",
       " 'sopa': 1,\n",
       " 'sophia': 1,\n",
       " 'sou': 4,\n",
       " 'sozinha': 1,\n",
       " 'sozinho': 1,\n",
       " 'stan': 1,\n",
       " 'stts': 1,\n",
       " 'sua': 5,\n",
       " 'sucrilhos': 1,\n",
       " 'suja': 1,\n",
       " 'sujei': 1,\n",
       " 'superior': 2,\n",
       " 'surreal': 1,\n",
       " 'são': 1,\n",
       " 'só': 19,\n",
       " 'ta': 3,\n",
       " 'tadinho': 1,\n",
       " 'talento': 1,\n",
       " 'talvez': 1,\n",
       " 'também': 1,\n",
       " 'tanto': 4,\n",
       " 'tao': 1,\n",
       " 'tava': 1,\n",
       " 'tbm': 3,\n",
       " 'td': 1,\n",
       " 'te': 6,\n",
       " 'team': 2,\n",
       " 'tem': 15,\n",
       " 'tempo': 2,\n",
       " 'temporada': 1,\n",
       " 'tenho': 1,\n",
       " 'tenta': 1,\n",
       " 'tentar': 2,\n",
       " 'tentei': 1,\n",
       " 'ter': 2,\n",
       " 'tesão': 1,\n",
       " 'teve': 2,\n",
       " 'tia': 3,\n",
       " 'tiago': 1,\n",
       " 'tinha': 3,\n",
       " 'tipo': 1,\n",
       " 'tirando': 1,\n",
       " 'tirar': 1,\n",
       " 'to': 9,\n",
       " 'toddy': 264,\n",
       " 'toddynho': 1,\n",
       " 'toddys': 1,\n",
       " 'toddytoddy': 1,\n",
       " 'todo': 3,\n",
       " 'toma': 1,\n",
       " 'tomando': 2,\n",
       " 'tomar': 8,\n",
       " 'tombo': 1,\n",
       " 'tomei': 5,\n",
       " 'tomem': 1,\n",
       " 'tomo': 2,\n",
       " 'tornará': 4,\n",
       " 'toronto': 1,\n",
       " 'torradas': 1,\n",
       " 'torrado': 1,\n",
       " 'treta': 1,\n",
       " 'troca': 2,\n",
       " 'trollagens': 1,\n",
       " 'trollou': 1,\n",
       " 'tu': 4,\n",
       " 'tua': 2,\n",
       " 'tudo': 1,\n",
       " 'turismo': 1,\n",
       " 'tá': 7,\n",
       " 'tão': 2,\n",
       " 'tédio': 1,\n",
       " 'têm': 1,\n",
       " 'tô': 5,\n",
       " 'ultimamente': 1,\n",
       " 'um': 22,\n",
       " 'uma': 28,\n",
       " 'umas': 1,\n",
       " 'unf': 1,\n",
       " 'uns': 1,\n",
       " 'urretada': 1,\n",
       " 'usei': 1,\n",
       " 'utilidade': 1,\n",
       " 'vaca': 3,\n",
       " 'vacilou': 1,\n",
       " 'vai': 6,\n",
       " 'vamos': 1,\n",
       " 'vcs': 2,\n",
       " 'veio': 1,\n",
       " 'vem': 3,\n",
       " 'vende': 1,\n",
       " 'vendendo': 1,\n",
       " 'venezuelana': 1,\n",
       " 'verdade': 11,\n",
       " 'versa': 1,\n",
       " 'vez': 1,\n",
       " 'vezes': 4,\n",
       " 'vi': 1,\n",
       " 'vice': 1,\n",
       " 'viciada': 1,\n",
       " 'vida': 4,\n",
       " 'video': 1,\n",
       " 'vidro': 1,\n",
       " 'vieira': 1,\n",
       " 'vinha': 1,\n",
       " 'vira': 4,\n",
       " 'visual': 1,\n",
       " 'vitamina': 1,\n",
       " 'viu': 4,\n",
       " 'viver': 1,\n",
       " 'vizinho': 1,\n",
       " 'vntd': 1,\n",
       " 'vo': 2,\n",
       " 'voce': 52,\n",
       " 'vocês': 2,\n",
       " 'volta': 1,\n",
       " 'voltar': 1,\n",
       " 'vontade': 5,\n",
       " 'vou': 4,\n",
       " 'vovó': 2,\n",
       " 'vtmnc': 1,\n",
       " 'vtnc': 1,\n",
       " 'vê': 1,\n",
       " 'ví': 1,\n",
       " 'vício': 1,\n",
       " 'vídeo': 3,\n",
       " 'waffer': 1,\n",
       " 'whindersson': 1,\n",
       " 'wpp': 1,\n",
       " 'x': 2,\n",
       " 'xiaxia': 2,\n",
       " 'yas': 1,\n",
       " 'yg': 1,\n",
       " 'yoongi': 1,\n",
       " 'zuar': 1,\n",
       " '{': 1,\n",
       " '}': 1,\n",
       " '~ace': 1,\n",
       " '°': 2,\n",
       " 'às': 1,\n",
       " 'álcool': 1,\n",
       " 'çldfasçdojat': 1,\n",
       " 'é': 79,\n",
       " 'ícone': 1,\n",
       " 'óbvio': 2,\n",
       " 'ótimo': 1,\n",
       " 'único': 1,\n",
       " '—': 24,\n",
       " '‘tatuagem': 1,\n",
       " '“mágico”': 1,\n",
       " '“namore': 1,\n",
       " '“te': 1,\n",
       " '•': 2,\n",
       " '●': 1,\n",
       " '♡': 1,\n",
       " '♥': 1,\n",
       " '✌': 1,\n",
       " '❤': 3,\n",
       " '➫': 4,\n",
       " '️': 1,\n",
       " '🍻': 1,\n",
       " '🎤': 1,\n",
       " '🎵': 1,\n",
       " '🏻': 1,\n",
       " '😂': 7,\n",
       " '😌': 1,\n",
       " '😍': 4,\n",
       " '😏': 1,\n",
       " '😜': 1,\n",
       " '😡': 4,\n",
       " '😪': 3,\n",
       " '😭': 1,\n",
       " '🤔': 2,\n",
       " '\\U0001f92e': 3}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preenche_listas(dic, palav, repet, prob):\n",
    "    for key in dic:\n",
    "        palav.append(key)\n",
    "        repet.append(dic[key])\n",
    "        prob.append((dic[key]/len(dic))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal_geral = []\n",
    "rep_geral = []\n",
    "prob_geral = []\n",
    "preenche_listas(t_pal, pal_geral, rep_geral, prob_geral)\n",
    "\n",
    "pal_rel = []\n",
    "rep_rel = []\n",
    "prob_rel = []\n",
    "preenche_listas(t_pal_rel, pal_rel, rep_rel, prob_rel)\n",
    "\n",
    "pal_irrel = []\n",
    "rep_irrel = []\n",
    "prob_irrel = []\n",
    "preenche_listas(t_pal_irrel, pal_irrel, rep_irrel, prob_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_g = pd.DataFrame({'palavra': pal_geral, \n",
    "                     'repeticao': rep_geral, \n",
    "                     'probabilidade': prob_geral})\n",
    "\n",
    "db_rel = pd.DataFrame({'palavra': pal_rel, \n",
    "                       'repeticao': rep_rel, \n",
    "                       'probabilidade': prob_rel})\n",
    "\n",
    "db_irrel = pd.DataFrame({'palavra': pal_irrel, \n",
    "                         'repeticao': rep_irrel, \n",
    "                         'probabilidade': prob_irrel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = frase\n",
    "# n = numerto total de palavras\n",
    "\n",
    "lista_de_stopwords = ['uma', 'um', 'uns', 'das', 'que', 'com']\n",
    "\n",
    "n_r = db_rel.repeticao.sum()\n",
    "n_i = db_irrel.repeticao.sum()\n",
    "\n",
    "def acha_probabilidade_relevante(string, n):\n",
    "    frase = string.split(' ')\n",
    "    total = 1\n",
    "    for palavra in frase:\n",
    "        if palavra in lista_de_stopwords:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                total = total * ((int(db_rel[db_rel.palavra == palavra].repeticao)+1)/(n+(len(pal_geral))))\n",
    "            except:\n",
    "                total = total * (0+1)/(n+(len(pal_geral)))\n",
    "    return total*100\n",
    "\n",
    "def acha_probabilidade_irrelevante(string, n):\n",
    "    frase = string.split(' ')\n",
    "    total = 1\n",
    "    for palavra in frase:\n",
    "        if palavra in lista_de_stopwords:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                total = total * ((int(db_irrel[db_irrel.palavra == palavra].repeticao)+1)/(n+(len(pal_geral))))\n",
    "            except:\n",
    "                total = total * (0+1)/(n+(len(pal_geral)))\n",
    "    return total*100\n",
    "\n",
    "def defini_relevancia(frase):\n",
    "    if acha_probabilidade_relevante(frase, n_r) > acha_probabilidade_irrelevante(frase, n_i):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.565248059543184e-15"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acha_probabilidade_relevante('alguem faz toddy quentinho pra mim', n_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.565026316634515e-15"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acha_probabilidade_irrelevante('alguem faz toddy quentinho pra mim', n_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defini_relevancia('alguem faz toddy quentinho mim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>repeticao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt</td>\n",
       "      <td>9.813084</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tem</td>\n",
       "      <td>2.570093</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uma</td>\n",
       "      <td>3.738318</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loja</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  probabilidade  repeticao\n",
       "0      rt       9.813084         42\n",
       "1     tem       2.570093         11\n",
       "2     uma       3.738318         16\n",
       "3    loja       0.233645          1\n",
       "4      na       0.934579          4"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_rel.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>verifica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @fsox7: #nãoconfioemgenteque acha que toddy...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @srdeabo: o toddy mudou de boi kkkkkkkkkk h...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@tioorochi vamos fazer tráfico\\n\\nde toddy?</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia  verifica\n",
       "0  rt @fsox7: #nãoconfioemgenteque acha que toddy...           1       NaN\n",
       "1  rt @srdeabo: o toddy mudou de boi kkkkkkkkkk h...           0       NaN\n",
       "2        @tioorochi vamos fazer tráfico\\n\\nde toddy?           1       NaN"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_toddy_teste.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_lista():\n",
    "    lista = []\n",
    "    cria_lista_de_tweets(lista, db_toddy_teste.Teste)\n",
    "    separa_palavras(lista)\n",
    "    replace_words(lista, wtf_list, wtf_list2, li1, li2)\n",
    "    replace_words(lista, wtf_list, wtf_list2, li1, li2)\n",
    "    \n",
    "    lista2 = []\n",
    "    for e in lista:\n",
    "        f = ' '.join(e)\n",
    "        lista2.append(f)\n",
    "    \n",
    "    lista_automatica = []\n",
    "    \n",
    "    for tweet in lista2:\n",
    "        lista_automatica.append(defini_relevancia(tweet))\n",
    "\n",
    "    lista_manual = []\n",
    "    cria_lista_de_tweets(lista_manual, db_toddy_teste.Relevancia)\n",
    "    \n",
    "    lis = [lista_manual, lista_automatica]\n",
    "    \n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_teste = cria_lista()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...\n",
       "1    [1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis_teste2 = pd.Series(lis_teste)\n",
    "lis_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 98 ocorrencias de relevancia = 1\n",
      "Há 102 ocorrencias de irrelevancia = 0\n"
     ]
    }
   ],
   "source": [
    "soma_1 = 0\n",
    "soma_0 = 0\n",
    "for e in lis_teste2[1]:\n",
    "    if e == 1:\n",
    "        soma_1 += 1\n",
    "    else:\n",
    "        soma_0 += 1\n",
    "        \n",
    "print('Há {0} ocorrencias de relevancia = 1'.format(soma_1))\n",
    "print('Há {0} ocorrencias de irrelevancia = 0'.format(soma_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica(lis):\n",
    "    soma = 0\n",
    "    i = 0\n",
    "    for e in lis[0]:\n",
    "        if lis[0][i] == lis[1][i]:\n",
    "            soma += 1\n",
    "        i += 1\n",
    "                \n",
    "    valor = (soma/len(lis[0])) * 100\n",
    "    \n",
    "    return print('Em comparação com a relevancia dada manuamente a relevancia dada pelo seu código é de {0}%'.format(valor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em comparação com a relevancia dada manuamente a relevancia dada pelo seu código é de 76.0%\n"
     ]
    }
   ],
   "source": [
    "verifica(lis_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
