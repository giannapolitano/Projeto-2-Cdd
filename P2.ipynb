{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from emoji import UNICODE_EMOJI \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_toddy = pd.read_excel('tweets_toddy_201809110116.xlsx', sheet_name = 0)\n",
    "db_toddy_teste = pd.read_excel('tweets_toddy_201809110116.xlsx', sheet_name = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "tweets_rel = []\n",
    "tweets_irrel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_lista_de_tweets(lista, local):\n",
    "    for tweet in local:\n",
    "        lista.append(tweet)\n",
    "\n",
    "def cria_lista_de_tweets_com_relevancia(lista, valor):\n",
    "    for tweet in db_toddy.Treinamento[db_toddy.Relevancia == valor]:\n",
    "        lista.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cria_lista_de_tweets(tweets, db_toddy.Treinamento)\n",
    "cria_lista_de_tweets_com_relevancia(tweets_rel, 1)\n",
    "cria_lista_de_tweets_com_relevancia(tweets_irrel, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista):\n",
    "    j = 0\n",
    "    for tweet in lista:\n",
    "        for letra in tweet:\n",
    "            if letra in UNICODE_EMOJI:\n",
    "                tweet = tweet.replace(letra,' {0} '.format(letra))\n",
    "        lista[j] = tweet.split(' ')\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "separa_palavras(tweets)\n",
    "separa_palavras(tweets_rel)\n",
    "separa_palavras(tweets_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf_list = [':','\"', \"'\", '/', '...', ',', '#', ';', '$', '!', '?', '.', '‚Ä¶', '\\t', '%', '(', ')', '&', '*','-', \n",
    "           '0','1','2','3','4','5','6','7','8','9']\n",
    "wtf_list2 = ['http', '@']\n",
    "\n",
    "li1 = ['vc', 'voc√™', 'qm', '+', 's', 'n', 'n√£o', 'algu√©m']\n",
    "li2 = ['voce', 'voc√™', 'quem', 'mais', 'sim', 'nao', 'nao', 'alguem']\n",
    "\n",
    "def replace_words(lista_principal, wtf, wtf2, l1, l2):\n",
    "    for lista in lista_principal:\n",
    "        for e in wtf:\n",
    "            for palavra in lista:\n",
    "                if palavra == '':\n",
    "                    lista.remove(palavra)\n",
    "                if e in palavra:\n",
    "                    palavra2 = palavra.replace(e, '')\n",
    "                    lista.remove(palavra)\n",
    "                    lista.append(palavra2)\n",
    "        \n",
    "        for palavra in lista:\n",
    "            if 'kkk' in palavra:\n",
    "                lista.remove(palavra)\n",
    "            elif 'aaa' in palavra:\n",
    "                lista.remove(palavra)\n",
    "            elif 'gtgt' in palavra:\n",
    "                lista.remove(palavra)\n",
    "            elif '\\n' in palavra:\n",
    "                palavra2 = (palavra.replace('\\n', ' ')).split(' ')\n",
    "                lista.remove(palavra)\n",
    "                for e in palavra2:\n",
    "                    lista.append(e)\n",
    "                \n",
    "        for palavra in lista:\n",
    "            for f in wtf2:\n",
    "                if f in palavra:\n",
    "                    lista.remove(palavra)\n",
    "                    \n",
    "        for palavra in lista:\n",
    "            i = 0\n",
    "            for e in li1:\n",
    "                if palavra == e:\n",
    "                    palavra2 = palavra.replace(e, li2[0])\n",
    "                    lista.remove(palavra)\n",
    "                    lista.append(palavra2)\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_words(tweets, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_rel, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_irrel, wtf_list, wtf_list2, li1, li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_words(tweets, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_rel, wtf_list, wtf_list2, li1, li2)\n",
    "replace_words(tweets_irrel, wtf_list, wtf_list2, li1, li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pal = {}\n",
    "t_pal_rel = {}\n",
    "t_pal_irrel = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conta_palavras(lista, dic):\n",
    "    for tweet in lista:\n",
    "        for palavra in tweet:\n",
    "            if palavra not in dic:\n",
    "                dic[palavra] = 1\n",
    "            else:\n",
    "                dic[palavra] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "conta_palavras(tweets, t_pal)\n",
    "conta_palavras(tweets_rel, t_pal_rel)\n",
    "conta_palavras(tweets_irrel, t_pal_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 4,\n",
       " '#luansantanatv': 1,\n",
       " 'B': 2,\n",
       " 'Bpersonagem': 1,\n",
       " 'a': 26,\n",
       " 'aben√ßoar': 1,\n",
       " 'acabei': 1,\n",
       " 'acabou': 1,\n",
       " 'aceita': 12,\n",
       " 'acha': 13,\n",
       " 'achei': 3,\n",
       " 'acho': 1,\n",
       " 'achocolatado': 3,\n",
       " 'achocolotado': 1,\n",
       " 'aconteceu': 1,\n",
       " 'acredito': 1,\n",
       " 'af': 2,\n",
       " 'afeira': 1,\n",
       " 'after': 1,\n",
       " 'agora': 5,\n",
       " 'agr': 2,\n",
       " 'ah': 1,\n",
       " 'ahhhh': 1,\n",
       " 'ahsjaush': 1,\n",
       " 'ai': 3,\n",
       " 'ainda': 6,\n",
       " 'ajudou': 1,\n",
       " 'algum': 1,\n",
       " 'alguma': 1,\n",
       " 'ama': 1,\n",
       " 'american': 1,\n",
       " 'amiga': 1,\n",
       " 'amo': 7,\n",
       " 'amor': 4,\n",
       " 'am√©m': 1,\n",
       " 'and': 1,\n",
       " 'anos': 1,\n",
       " 'anuncia': 1,\n",
       " 'ao': 5,\n",
       " 'aou': 1,\n",
       " 'apagar': 3,\n",
       " 'apanhar': 1,\n",
       " 'apenas': 1,\n",
       " 'aposto': 1,\n",
       " 'ap√≥s': 1,\n",
       " 'aq': 2,\n",
       " 'aquele': 2,\n",
       " 'aqui': 4,\n",
       " 'aqu√°rio': 1,\n",
       " 'ardendo': 1,\n",
       " 'army': 1,\n",
       " 'as': 5,\n",
       " 'assim': 2,\n",
       " 'assistir': 2,\n",
       " 'atacantes': 1,\n",
       " 'aten√ß√£o': 1,\n",
       " 'atr√°s': 1,\n",
       " 'at√©': 1,\n",
       " 'avenida': 1,\n",
       " 'a√≠': 1,\n",
       " 'baby': 2,\n",
       " 'bacon': 1,\n",
       " 'bagun√ßar': 1,\n",
       " 'banana': 2,\n",
       " 'banner': 1,\n",
       " 'barato': 1,\n",
       " 'basicamente': 1,\n",
       " 'bati': 1,\n",
       " 'bb': 1,\n",
       " 'bebendo': 1,\n",
       " 'beber': 2,\n",
       " 'bem': 3,\n",
       " 'bermuda': 1,\n",
       " 'bgls': 1,\n",
       " 'biscoito': 4,\n",
       " 'bitch': 1,\n",
       " 'boa': 8,\n",
       " 'boas': 1,\n",
       " 'boi': 83,\n",
       " 'bolacha': 2,\n",
       " 'bolinhas': 1,\n",
       " 'bolo': 1,\n",
       " 'bolsonaro': 1,\n",
       " 'bom': 16,\n",
       " 'bonito': 1,\n",
       " 'bonoro': 1,\n",
       " 'borocoxo': 1,\n",
       " 'bozonaro': 1,\n",
       " 'branca': 1,\n",
       " 'branco': 1,\n",
       " 'brasil': 2,\n",
       " 'brasileiro': 1,\n",
       " 'brigadeiro': 4,\n",
       " 'busca': 1,\n",
       " 'cabe√ßa': 1,\n",
       " 'cachorro': 1,\n",
       " 'cada': 1,\n",
       " 'cafeteria': 1,\n",
       " 'caf√©': 6,\n",
       " 'caganeira': 1,\n",
       " 'caiu': 1,\n",
       " 'caminho': 1,\n",
       " 'candidatar': 1,\n",
       " 'cara': 4,\n",
       " 'caralho': 3,\n",
       " 'carne': 1,\n",
       " 'carreira': 1,\n",
       " 'casa': 6,\n",
       " 'casal': 1,\n",
       " 'cata': 1,\n",
       " 'causa': 1,\n",
       " 'cereal': 2,\n",
       " 'certo': 1,\n",
       " 'cerveja': 2,\n",
       " 'ces': 1,\n",
       " 'chama': 1,\n",
       " 'chamar': 2,\n",
       " 'chanyeol': 2,\n",
       " 'chega': 1,\n",
       " 'chegar': 1,\n",
       " 'chegou': 1,\n",
       " 'cheguei': 1,\n",
       " 'cheio': 1,\n",
       " 'cidade': 1,\n",
       " 'cima': 1,\n",
       " 'cinema': 1,\n",
       " 'cobertor': 1,\n",
       " 'coisa': 4,\n",
       " 'cole': 1,\n",
       " 'coloca': 1,\n",
       " 'colocaram': 1,\n",
       " 'com': 44,\n",
       " 'come': 1,\n",
       " 'comediante': 1,\n",
       " 'comem': 1,\n",
       " 'comendo': 1,\n",
       " 'comente': 1,\n",
       " 'comer': 2,\n",
       " 'comerciais': 1,\n",
       " 'come√ßa': 2,\n",
       " 'come√ßando': 1,\n",
       " 'comi': 2,\n",
       " 'como': 11,\n",
       " 'compara': 1,\n",
       " 'comparar': 1,\n",
       " 'completar': 1,\n",
       " 'complexo': 1,\n",
       " 'compraram': 1,\n",
       " 'comprasse': 1,\n",
       " 'comprei': 2,\n",
       " 'comprou': 2,\n",
       " 'conceitos': 1,\n",
       " 'condensado': 1,\n",
       " 'consigo': 1,\n",
       " 'contratar': 1,\n",
       " 'conversando': 2,\n",
       " 'conversar': 1,\n",
       " 'convite': 1,\n",
       " 'copao': 1,\n",
       " 'copo': 4,\n",
       " 'copos': 1,\n",
       " 'coragem': 4,\n",
       " 'cora√ß√µes': 1,\n",
       " 'coxinha': 1,\n",
       " 'crian√ßa': 1,\n",
       " 'crise': 1,\n",
       " 'cunhado': 1,\n",
       " 'custava': 1,\n",
       " 'cvsa': 2,\n",
       " 'cy': 1,\n",
       " 'c√∫': 1,\n",
       " 'd': 2,\n",
       " 'da': 15,\n",
       " 'dan√ßando': 1,\n",
       " 'daqueles': 1,\n",
       " 'dar': 2,\n",
       " 'das': 2,\n",
       " 'da√≠': 1,\n",
       " 'de': 149,\n",
       " 'debaixo': 1,\n",
       " 'defeito': 1,\n",
       " 'deficiente': 1,\n",
       " 'deixa': 1,\n",
       " 'deixar': 1,\n",
       " 'depende': 1,\n",
       " 'depois': 1,\n",
       " 'derramei': 1,\n",
       " 'desde': 1,\n",
       " 'desgrama': 1,\n",
       " 'desistiu': 1,\n",
       " 'deus': 2,\n",
       " 'dia': 6,\n",
       " 'diferente': 1,\n",
       " 'dimais': 1,\n",
       " 'dinheiro': 1,\n",
       " 'direito': 1,\n",
       " 'discuta': 1,\n",
       " 'discutindo': 2,\n",
       " 'dissolve': 1,\n",
       " 'ditadura': 1,\n",
       " 'divulgar': 1,\n",
       " 'dm': 2,\n",
       " 'dms': 1,\n",
       " 'do': 32,\n",
       " 'doido': 1,\n",
       " 'dois': 3,\n",
       " 'domingo': 1,\n",
       " 'doq': 1,\n",
       " 'dormir': 2,\n",
       " 'dos': 2,\n",
       " 'duas': 1,\n",
       " 'd√°': 1,\n",
       " 'd√≠vidas': 1,\n",
       " 'd√≥rim√™': 1,\n",
       " 'e': 64,\n",
       " 'el': 1,\n",
       " 'ela': 1,\n",
       " 'elas': 1,\n",
       " 'ele': 7,\n",
       " 'em': 10,\n",
       " 'emily': 1,\n",
       " 'encontrei': 1,\n",
       " 'enfrentassem': 1,\n",
       " 'enfrentava': 1,\n",
       " 'enjoado': 1,\n",
       " 'enjoo': 1,\n",
       " 'enquanto': 2,\n",
       " 'entendo': 3,\n",
       " 'ent√£o': 1,\n",
       " 'envelhecer‚Äô': 1,\n",
       " 'epis√≥dio': 1,\n",
       " 'era': 1,\n",
       " 'errada': 1,\n",
       " 'erro': 1,\n",
       " 'ervilha': 1,\n",
       " 'escreveu': 1,\n",
       " 'essa': 3,\n",
       " 'esse': 4,\n",
       " 'esta': 1,\n",
       " 'estado': 1,\n",
       " 'estar': 1,\n",
       " 'estrela': 1,\n",
       " 'estressada': 1,\n",
       " 'estresse': 1,\n",
       " 'estudando': 1,\n",
       " 'estudar': 1,\n",
       " 'est√°': 2,\n",
       " 'est√°dio': 1,\n",
       " 'eternamente': 1,\n",
       " 'eu': 50,\n",
       " 'europ√©ia': 1,\n",
       " 'exclui': 1,\n",
       " 'existe': 1,\n",
       " 'expe': 1,\n",
       " 'fala': 11,\n",
       " 'falam': 1,\n",
       " 'falar': 5,\n",
       " 'falou': 1,\n",
       " 'falta': 1,\n",
       " 'fam√≠lia': 1,\n",
       " 'fase': 2,\n",
       " 'fato': 1,\n",
       " 'fatos': 1,\n",
       " 'fav': 1,\n",
       " 'faz': 3,\n",
       " 'fazendo': 2,\n",
       " 'fazer': 1,\n",
       " 'fazia': 1,\n",
       " 'fa√ßo': 1,\n",
       " 'feia': 1,\n",
       " 'feio': 1,\n",
       " 'feliz': 1,\n",
       " 'festeja': 1,\n",
       " 'ffstore': 1,\n",
       " 'fica': 3,\n",
       " 'ficar': 3,\n",
       " 'ficou': 3,\n",
       " 'filh√£o': 1,\n",
       " 'filme': 1,\n",
       " 'fiquei': 1,\n",
       " 'firmino': 1,\n",
       " 'fiz': 4,\n",
       " 'fizestes': 1,\n",
       " 'fofo': 1,\n",
       " 'foi': 11,\n",
       " 'fome': 1,\n",
       " 'for': 1,\n",
       " 'fora': 1,\n",
       " 'forte': 1,\n",
       " 'fosse': 2,\n",
       " 'foto': 2,\n",
       " 'frase': 1,\n",
       " 'frente': 1,\n",
       " 'freskolita': 1,\n",
       " 'friends': 1,\n",
       " 'frio': 1,\n",
       " 'fruta': 1,\n",
       " 'fui': 6,\n",
       " 'funk': 1,\n",
       " 'f√°cil': 3,\n",
       " 'f√£s': 1,\n",
       " 'f√≠gado': 1,\n",
       " 'gabes': 1,\n",
       " 'gaga': 1,\n",
       " 'galera': 1,\n",
       " 'ganhar': 2,\n",
       " 'garotos': 1,\n",
       " 'garrafinha': 1,\n",
       " 'gases': 1,\n",
       " 'gastar': 1,\n",
       " 'gastron√¥micamente': 1,\n",
       " 'ga√∫chos': 1,\n",
       " 'gelado': 1,\n",
       " 'gema': 1,\n",
       " 'gente': 7,\n",
       " 'gif': 1,\n",
       " 'gira': 1,\n",
       " 'golpes': 1,\n",
       " 'gost': 1,\n",
       " 'gosta': 8,\n",
       " 'gostar': 1,\n",
       " 'gostei': 1,\n",
       " 'gosto': 4,\n",
       " 'grita': 1,\n",
       " 'gritou': 1,\n",
       " 'guri': 1,\n",
       " 'hahahahahaha': 1,\n",
       " 'happyyy': 1,\n",
       " 'hard': 1,\n",
       " 'hehehehehe': 1,\n",
       " 'hj': 2,\n",
       " 'hoje': 2,\n",
       " 'horr√≠vel': 1,\n",
       " 'hrs': 1,\n",
       " 'humanidade': 1,\n",
       " 'humano': 1,\n",
       " 'h√°': 2,\n",
       " 'i': 1,\n",
       " 'ia': 4,\n",
       " 'ideia': 1,\n",
       " 'igual': 2,\n",
       " 'iguaria': 1,\n",
       " 'im': 1,\n",
       " 'importantes': 1,\n",
       " 'impossivel': 1,\n",
       " 'indicava': 1,\n",
       " 'infernal': 1,\n",
       " 'inferno': 1,\n",
       " 'influencers': 1,\n",
       " 'ingrid': 1,\n",
       " 'inteiro': 1,\n",
       " 'inventou': 1,\n",
       " 'inv√©s': 3,\n",
       " 'ir': 2,\n",
       " 'iria': 1,\n",
       " 'irm√£': 1,\n",
       " 'isso': 3,\n",
       " 'ja': 3,\n",
       " 'jamais': 4,\n",
       " 'jean': 1,\n",
       " 'jeito': 2,\n",
       " 'jikooka': 1,\n",
       " 'jil√≥': 1,\n",
       " 'jimin': 1,\n",
       " 'joga': 1,\n",
       " 'jorge': 1,\n",
       " 'jr': 1,\n",
       " 'ju': 2,\n",
       " 'juan': 1,\n",
       " 'jungkook': 1,\n",
       " 'juntasse': 1,\n",
       " 'j√°': 4,\n",
       " 'kakakakakak': 1,\n",
       " 'kao': 1,\n",
       " 'karina': 1,\n",
       " 'kavinsky': 1,\n",
       " 'ketchup': 1,\n",
       " 'la': 6,\n",
       " 'ladr√£o': 1,\n",
       " 'lady': 1,\n",
       " 'lara': 1,\n",
       " 'laricando': 1,\n",
       " 'lata': 1,\n",
       " 'lc': 1,\n",
       " 'lei': 1,\n",
       " 'leite': 20,\n",
       " 'lembrando': 1,\n",
       " 'lembrar': 1,\n",
       " 'levantar': 1,\n",
       " 'levantou': 1,\n",
       " 'licen√ßa': 1,\n",
       " 'ligado': 1,\n",
       " 'liked': 1,\n",
       " 'limonada': 1,\n",
       " 'lista': 1,\n",
       " 'litoral': 1,\n",
       " 'lixa': 1,\n",
       " 'loca': 1,\n",
       " 'logo': 1,\n",
       " 'loja': 1,\n",
       " 'losejacob': 1,\n",
       " 'luanetes': 1,\n",
       " 'luansantana': 1,\n",
       " 'lula': 2,\n",
       " 'luz': 1,\n",
       " 'l√°': 2,\n",
       " 'maior': 2,\n",
       " 'maioria': 1,\n",
       " 'mais': 10,\n",
       " 'malta': 1,\n",
       " 'maluco': 1,\n",
       " 'maluquice': 1,\n",
       " 'mam√£o': 1,\n",
       " 'manh√£': 2,\n",
       " 'mano': 7,\n",
       " 'mar': 1,\n",
       " 'maravilhoso': 1,\n",
       " 'marina': 1,\n",
       " 'marketing': 1,\n",
       " 'mas': 10,\n",
       " 'me': 10,\n",
       " 'medos': 1,\n",
       " 'melhor': 53,\n",
       " 'melhores': 2,\n",
       " 'meme': 1,\n",
       " 'memo': 1,\n",
       " 'meninas': 1,\n",
       " 'menos': 2,\n",
       " 'mentira': 1,\n",
       " 'mentiu': 1,\n",
       " 'mercado': 1,\n",
       " 'merda': 4,\n",
       " 'mesma': 1,\n",
       " 'mesmo': 3,\n",
       " 'meu': 15,\n",
       " 'meus': 2,\n",
       " 'mim': 5,\n",
       " 'mina': 1,\n",
       " 'minha': 10,\n",
       " 'miojin': 1,\n",
       " 'mirou': 1,\n",
       " 'misto': 1,\n",
       " 'misturei': 2,\n",
       " 'mole': 1,\n",
       " 'moral': 1,\n",
       " 'morava': 1,\n",
       " 'moreira': 1,\n",
       " 'morrendo': 1,\n",
       " 'morrer': 1,\n",
       " 'mortadela': 1,\n",
       " 'mo√≠da': 1,\n",
       " 'mpn': 1,\n",
       " 'msc': 1,\n",
       " 'mt': 5,\n",
       " 'mto': 1,\n",
       " 'mudar': 1,\n",
       " 'mudou': 81,\n",
       " 'muitas': 1,\n",
       " 'muito': 7,\n",
       " 'mulher': 1,\n",
       " 'mundo': 4,\n",
       " 'm√°quinas': 1,\n",
       " 'm√£e': 4,\n",
       " 'm√≠dia': 2,\n",
       " 'm√∫sica': 1,\n",
       " 'na': 16,\n",
       " 'nada': 5,\n",
       " 'nao': 5,\n",
       " 'nariz': 1,\n",
       " 'nasce': 1,\n",
       " 'nasceu': 4,\n",
       " 'nay': 1,\n",
       " 'ne': 1,\n",
       " 'neg√≥cio': 1,\n",
       " 'neil': 1,\n",
       " 'nem': 3,\n",
       " 'nescal': 1,\n",
       " 'nescau': 84,\n",
       " 'nescautoddy': 1,\n",
       " 'nessa': 2,\n",
       " 'ngm': 1,\n",
       " 'niguem': 9,\n",
       " 'ningu√©m': 5,\n",
       " 'nisso': 1,\n",
       " 'nmrl': 1,\n",
       " 'no': 11,\n",
       " 'noite': 5,\n",
       " 'nojento': 1,\n",
       " 'nordestino': 1,\n",
       " 'normal': 2,\n",
       " 'nos': 2,\n",
       " 'nossa': 3,\n",
       " 'not√≠cias': 1,\n",
       " 'nova': 1,\n",
       " 'novo': 1,\n",
       " 'nu': 1,\n",
       " 'num': 1,\n",
       " 'numa': 2,\n",
       " 'nunca': 3,\n",
       " 'nunes': 1,\n",
       " 'n√£oconfioemgenteque': 14,\n",
       " 'n√©': 2,\n",
       " 'n√≥s': 1,\n",
       " 'o': 123,\n",
       " 'obrigado': 1,\n",
       " 'odeia': 1,\n",
       " 'odeio': 1,\n",
       " 'odiada': 1,\n",
       " 'oficialmente': 1,\n",
       " 'olha': 2,\n",
       " 'olhares': 1,\n",
       " 'olhe': 2,\n",
       " 'onde': 1,\n",
       " 'opini√£o': 1,\n",
       " 'oq': 1,\n",
       " 'os': 3,\n",
       " 'otaria': 1,\n",
       " 'ou': 13,\n",
       " 'out': 1,\n",
       " 'outro': 1,\n",
       " 'outros': 1,\n",
       " 'ovo': 2,\n",
       " 'ovomaltine': 1,\n",
       " 'p': 3,\n",
       " 'paga': 1,\n",
       " 'pai': 1,\n",
       " 'para': 6,\n",
       " 'parece': 1,\n",
       " 'parte': 1,\n",
       " 'participa√ß√£o': 1,\n",
       " 'party': 1,\n",
       " 'passada': 1,\n",
       " 'passado': 1,\n",
       " 'passar': 1,\n",
       " 'patrocina': 1,\n",
       " 'pede': 1,\n",
       " 'pedi': 1,\n",
       " 'pediu': 2,\n",
       " 'pega': 1,\n",
       " 'pegasse': 1,\n",
       " 'pelo': 2,\n",
       " 'pensando': 1,\n",
       " 'percebi': 1,\n",
       " 'perdas': 2,\n",
       " 'perdem': 1,\n",
       " 'perdeu': 1,\n",
       " 'perguntando': 1,\n",
       " 'pergunteme': 1,\n",
       " 'pesada': 1,\n",
       " 'pessoas': 8,\n",
       " 'peter': 1,\n",
       " 'ph': 1,\n",
       " 'phodda': 1,\n",
       " 'pie': 1,\n",
       " 'pior': 1,\n",
       " 'pipow': 1,\n",
       " 'pode': 3,\n",
       " 'podem': 1,\n",
       " 'poderiam': 1,\n",
       " 'podrid√£o': 1,\n",
       " 'pois': 1,\n",
       " 'por': 5,\n",
       " 'porem': 1,\n",
       " 'porque': 3,\n",
       " 'por√©m': 1,\n",
       " 'posso': 1,\n",
       " 'poss√≠vel': 1,\n",
       " 'postei': 1,\n",
       " 'pote': 2,\n",
       " 'povoa': 1,\n",
       " 'pq': 6,\n",
       " 'pqp': 1,\n",
       " 'pra': 29,\n",
       " 'pranamorarcmgtemq': 1,\n",
       " 'prato': 1,\n",
       " 'precisa': 2,\n",
       " 'prefere': 10,\n",
       " 'preferem': 1,\n",
       " 'preferir': 1,\n",
       " 'prefiro': 2,\n",
       " 'pregui√ßa': 1,\n",
       " 'pressentimento': 1,\n",
       " 'presto': 1,\n",
       " 'presunto': 1,\n",
       " 'primeiro': 1,\n",
       " 'pro': 4,\n",
       " 'prof': 1,\n",
       " 'promete': 1,\n",
       " 'propaganda': 1,\n",
       " 'proposta': 1,\n",
       " 'prova': 1,\n",
       " 'provaram': 1,\n",
       " 'pr√≥pria': 1,\n",
       " 'pr√≥xima': 2,\n",
       " 'pr√≥ximo': 1,\n",
       " 'pudim': 1,\n",
       " 'puro,': 1,\n",
       " 'pur√™': 1,\n",
       " 'pus': 1,\n",
       " 'puta': 1,\n",
       " 'pvd': 1,\n",
       " 'p√£o': 6,\n",
       " 'p√©': 3,\n",
       " 'p√≥': 2,\n",
       " 'p√≥sferiado': 1,\n",
       " 'p√∫blica': 1,\n",
       " 'q': 20,\n",
       " 'qe': 1,\n",
       " 'qnd': 1,\n",
       " 'qq': 2,\n",
       " 'qualquer': 2,\n",
       " 'quando': 3,\n",
       " 'quase': 1,\n",
       " 'que': 107,\n",
       " 'quebrando': 1,\n",
       " 'queijo': 2,\n",
       " 'quem': 17,\n",
       " 'quente': 6,\n",
       " 'quenteee': 1,\n",
       " 'quer': 1,\n",
       " 'queria': 6,\n",
       " 'quero': 3,\n",
       " 'quest√£o': 1,\n",
       " 'que‚Äù': 1,\n",
       " 'quieto': 1,\n",
       " 'radical': 1,\n",
       " 'raffa': 1,\n",
       " 'raiva': 1,\n",
       " 'ralo': 1,\n",
       " 'reais': 1,\n",
       " 'realmente': 3,\n",
       " 'receber': 1,\n",
       " 'reclamou': 1,\n",
       " 'recusaram': 1,\n",
       " 'rec√≠proco': 1,\n",
       " 'registrado': 1,\n",
       " 'reina': 1,\n",
       " 'relat√≥rio': 1,\n",
       " 'renan': 1,\n",
       " 'repente': 1,\n",
       " 'resto': 1,\n",
       " 'rever': 1,\n",
       " 'revoltada': 1,\n",
       " 'rimas': 1,\n",
       " 'roberto': 1,\n",
       " 'role': 1,\n",
       " 'romario': 1,\n",
       " 'rosto': 1,\n",
       " 'roubar': 1,\n",
       " 'rt': 156,\n",
       " 'ruim': 2,\n",
       " 'ryca': 1,\n",
       " 'sabe': 1,\n",
       " 'saber': 5,\n",
       " 'sabia': 3,\n",
       " 'sala': 1,\n",
       " 'salve': 1,\n",
       " 'sal√°rio': 1,\n",
       " 'saudades': 1,\n",
       " 'sc': 1,\n",
       " 'se': 23,\n",
       " 'secret√°rio': 1,\n",
       " 'secura': 1,\n",
       " 'seguindo': 1,\n",
       " 'segunda': 2,\n",
       " 'segundadetremurasdv': 1,\n",
       " 'segundamente': 1,\n",
       " 'segurando': 1,\n",
       " 'sei': 10,\n",
       " 'seja': 1,\n",
       " 'sem': 1,\n",
       " 'semana': 1,\n",
       " 'sempre': 3,\n",
       " 'sensa√ß√£o': 1,\n",
       " 'sentir': 2,\n",
       " 'seokjin': 2,\n",
       " 'ser': 7,\n",
       " 'ser√°': 2,\n",
       " 'seu': 2,\n",
       " 'seus': 2,\n",
       " 'sim': 3,\n",
       " 'simm': 1,\n",
       " 'simples': 1,\n",
       " 'situa√ß√µes': 1,\n",
       " 'skate': 1,\n",
       " 'smksks': 1,\n",
       " 'so': 5,\n",
       " 'sobre': 3,\n",
       " 'sogra': 1,\n",
       " 'sono': 1,\n",
       " 'sopa': 1,\n",
       " 'sophia': 1,\n",
       " 'sou': 4,\n",
       " 'sozinha': 1,\n",
       " 'sozinho': 1,\n",
       " 'stan': 1,\n",
       " 'stts': 1,\n",
       " 'sua': 5,\n",
       " 'sucrilhos': 1,\n",
       " 'suja': 1,\n",
       " 'sujei': 1,\n",
       " 'superior': 2,\n",
       " 'surreal': 1,\n",
       " 's√£o': 1,\n",
       " 's√≥': 19,\n",
       " 'ta': 3,\n",
       " 'tadinho': 1,\n",
       " 'talento': 1,\n",
       " 'talvez': 1,\n",
       " 'tamb√©m': 1,\n",
       " 'tanto': 4,\n",
       " 'tao': 1,\n",
       " 'tava': 1,\n",
       " 'tbm': 3,\n",
       " 'td': 1,\n",
       " 'te': 6,\n",
       " 'team': 2,\n",
       " 'tem': 15,\n",
       " 'tempo': 2,\n",
       " 'temporada': 1,\n",
       " 'tenho': 1,\n",
       " 'tenta': 1,\n",
       " 'tentar': 2,\n",
       " 'tentei': 1,\n",
       " 'ter': 2,\n",
       " 'tes√£o': 1,\n",
       " 'teve': 2,\n",
       " 'tia': 3,\n",
       " 'tiago': 1,\n",
       " 'tinha': 3,\n",
       " 'tipo': 1,\n",
       " 'tirando': 1,\n",
       " 'tirar': 1,\n",
       " 'to': 9,\n",
       " 'toddy': 264,\n",
       " 'toddynho': 1,\n",
       " 'toddys': 1,\n",
       " 'toddytoddy': 1,\n",
       " 'todo': 3,\n",
       " 'toma': 1,\n",
       " 'tomando': 2,\n",
       " 'tomar': 8,\n",
       " 'tombo': 1,\n",
       " 'tomei': 5,\n",
       " 'tomem': 1,\n",
       " 'tomo': 2,\n",
       " 'tornar√°': 4,\n",
       " 'toronto': 1,\n",
       " 'torradas': 1,\n",
       " 'torrado': 1,\n",
       " 'treta': 1,\n",
       " 'troca': 2,\n",
       " 'trollagens': 1,\n",
       " 'trollou': 1,\n",
       " 'tu': 4,\n",
       " 'tua': 2,\n",
       " 'tudo': 1,\n",
       " 'turismo': 1,\n",
       " 't√°': 7,\n",
       " 't√£o': 2,\n",
       " 't√©dio': 1,\n",
       " 't√™m': 1,\n",
       " 't√¥': 5,\n",
       " 'ultimamente': 1,\n",
       " 'um': 22,\n",
       " 'uma': 28,\n",
       " 'umas': 1,\n",
       " 'unf': 1,\n",
       " 'uns': 1,\n",
       " 'urretada': 1,\n",
       " 'usei': 1,\n",
       " 'utilidade': 1,\n",
       " 'vaca': 3,\n",
       " 'vacilou': 1,\n",
       " 'vai': 6,\n",
       " 'vamos': 1,\n",
       " 'vcs': 2,\n",
       " 'veio': 1,\n",
       " 'vem': 3,\n",
       " 'vende': 1,\n",
       " 'vendendo': 1,\n",
       " 'venezuelana': 1,\n",
       " 'verdade': 11,\n",
       " 'versa': 1,\n",
       " 'vez': 1,\n",
       " 'vezes': 4,\n",
       " 'vi': 1,\n",
       " 'vice': 1,\n",
       " 'viciada': 1,\n",
       " 'vida': 4,\n",
       " 'video': 1,\n",
       " 'vidro': 1,\n",
       " 'vieira': 1,\n",
       " 'vinha': 1,\n",
       " 'vira': 4,\n",
       " 'visual': 1,\n",
       " 'vitamina': 1,\n",
       " 'viu': 4,\n",
       " 'viver': 1,\n",
       " 'vizinho': 1,\n",
       " 'vntd': 1,\n",
       " 'vo': 2,\n",
       " 'voce': 52,\n",
       " 'voc√™s': 2,\n",
       " 'volta': 1,\n",
       " 'voltar': 1,\n",
       " 'vontade': 5,\n",
       " 'vou': 4,\n",
       " 'vov√≥': 2,\n",
       " 'vtmnc': 1,\n",
       " 'vtnc': 1,\n",
       " 'v√™': 1,\n",
       " 'v√≠': 1,\n",
       " 'v√≠cio': 1,\n",
       " 'v√≠deo': 3,\n",
       " 'waffer': 1,\n",
       " 'whindersson': 1,\n",
       " 'wpp': 1,\n",
       " 'x': 2,\n",
       " 'xiaxia': 2,\n",
       " 'yas': 1,\n",
       " 'yg': 1,\n",
       " 'yoongi': 1,\n",
       " 'zuar': 1,\n",
       " '{': 1,\n",
       " '}': 1,\n",
       " '~ace': 1,\n",
       " '¬∞': 2,\n",
       " '√†s': 1,\n",
       " '√°lcool': 1,\n",
       " '√ßldfas√ßdojat': 1,\n",
       " '√©': 79,\n",
       " '√≠cone': 1,\n",
       " '√≥bvio': 2,\n",
       " '√≥timo': 1,\n",
       " '√∫nico': 1,\n",
       " '‚Äî': 24,\n",
       " '‚Äòtatuagem': 1,\n",
       " '‚Äúm√°gico‚Äù': 1,\n",
       " '‚Äúnamore': 1,\n",
       " '‚Äúte': 1,\n",
       " '‚Ä¢': 2,\n",
       " '‚óè': 1,\n",
       " '‚ô°': 1,\n",
       " '‚ô•': 1,\n",
       " '‚úå': 1,\n",
       " '‚ù§': 3,\n",
       " '‚û´': 4,\n",
       " 'Ô∏è': 1,\n",
       " 'üçª': 1,\n",
       " 'üé§': 1,\n",
       " 'üéµ': 1,\n",
       " 'üèª': 1,\n",
       " 'üòÇ': 7,\n",
       " 'üòå': 1,\n",
       " 'üòç': 4,\n",
       " 'üòè': 1,\n",
       " 'üòú': 1,\n",
       " 'üò°': 4,\n",
       " 'üò™': 3,\n",
       " 'üò≠': 1,\n",
       " 'ü§î': 2,\n",
       " '\\U0001f92e': 3}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preenche_listas(dic, palav, repet, prob):\n",
    "    for key in dic:\n",
    "        palav.append(key)\n",
    "        repet.append(dic[key])\n",
    "        prob.append((dic[key]/len(dic))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal_geral = []\n",
    "rep_geral = []\n",
    "prob_geral = []\n",
    "preenche_listas(t_pal, pal_geral, rep_geral, prob_geral)\n",
    "\n",
    "pal_rel = []\n",
    "rep_rel = []\n",
    "prob_rel = []\n",
    "preenche_listas(t_pal_rel, pal_rel, rep_rel, prob_rel)\n",
    "\n",
    "pal_irrel = []\n",
    "rep_irrel = []\n",
    "prob_irrel = []\n",
    "preenche_listas(t_pal_irrel, pal_irrel, rep_irrel, prob_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_g = pd.DataFrame({'palavra': pal_geral, \n",
    "                     'repeticao': rep_geral, \n",
    "                     'probabilidade': prob_geral})\n",
    "\n",
    "db_rel = pd.DataFrame({'palavra': pal_rel, \n",
    "                       'repeticao': rep_rel, \n",
    "                       'probabilidade': prob_rel})\n",
    "\n",
    "db_irrel = pd.DataFrame({'palavra': pal_irrel, \n",
    "                         'repeticao': rep_irrel, \n",
    "                         'probabilidade': prob_irrel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = frase\n",
    "# n = numerto total de palavras\n",
    "\n",
    "lista_de_stopwords = ['uma', 'um', 'uns', 'das', 'que', 'com']\n",
    "\n",
    "n_r = db_rel.repeticao.sum()\n",
    "n_i = db_irrel.repeticao.sum()\n",
    "\n",
    "def acha_probabilidade_relevante(string, n):\n",
    "    frase = string.split(' ')\n",
    "    total = 1\n",
    "    for palavra in frase:\n",
    "        if palavra in lista_de_stopwords:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                total = total * ((int(db_rel[db_rel.palavra == palavra].repeticao)+1)/(n+(len(pal_geral))))\n",
    "            except:\n",
    "                total = total * (0+1)/(n+(len(pal_geral)))\n",
    "    return total*100\n",
    "\n",
    "def acha_probabilidade_irrelevante(string, n):\n",
    "    frase = string.split(' ')\n",
    "    total = 1\n",
    "    for palavra in frase:\n",
    "        if palavra in lista_de_stopwords:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                total = total * ((int(db_irrel[db_irrel.palavra == palavra].repeticao)+1)/(n+(len(pal_geral))))\n",
    "            except:\n",
    "                total = total * (0+1)/(n+(len(pal_geral)))\n",
    "    return total*100\n",
    "\n",
    "def defini_relevancia(frase):\n",
    "    if acha_probabilidade_relevante(frase, n_r) > acha_probabilidade_irrelevante(frase, n_i):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.565248059543184e-15"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acha_probabilidade_relevante('alguem faz toddy quentinho pra mim', n_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.565026316634515e-15"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acha_probabilidade_irrelevante('alguem faz toddy quentinho pra mim', n_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defini_relevancia('alguem faz toddy quentinho mim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>probabilidade</th>\n",
       "      <th>repeticao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt</td>\n",
       "      <td>9.813084</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tem</td>\n",
       "      <td>2.570093</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uma</td>\n",
       "      <td>3.738318</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loja</td>\n",
       "      <td>0.233645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  palavra  probabilidade  repeticao\n",
       "0      rt       9.813084         42\n",
       "1     tem       2.570093         11\n",
       "2     uma       3.738318         16\n",
       "3    loja       0.233645          1\n",
       "4      na       0.934579          4"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_rel.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "      <th>verifica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @fsox7: #n√£oconfioemgenteque acha que toddy...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @srdeabo: o toddy mudou de boi kkkkkkkkkk h...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@tioorochi vamos fazer tr√°fico\\n\\nde toddy?</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia  verifica\n",
       "0  rt @fsox7: #n√£oconfioemgenteque acha que toddy...           1       NaN\n",
       "1  rt @srdeabo: o toddy mudou de boi kkkkkkkkkk h...           0       NaN\n",
       "2        @tioorochi vamos fazer tr√°fico\\n\\nde toddy?           1       NaN"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_toddy_teste.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_lista():\n",
    "    lista = []\n",
    "    cria_lista_de_tweets(lista, db_toddy_teste.Teste)\n",
    "    separa_palavras(lista)\n",
    "    replace_words(lista, wtf_list, wtf_list2, li1, li2)\n",
    "    replace_words(lista, wtf_list, wtf_list2, li1, li2)\n",
    "    \n",
    "    lista2 = []\n",
    "    for e in lista:\n",
    "        f = ' '.join(e)\n",
    "        lista2.append(f)\n",
    "    \n",
    "    lista_automatica = []\n",
    "    \n",
    "    for tweet in lista2:\n",
    "        lista_automatica.append(defini_relevancia(tweet))\n",
    "\n",
    "    lista_manual = []\n",
    "    cria_lista_de_tweets(lista_manual, db_toddy_teste.Relevancia)\n",
    "    \n",
    "    lis = [lista_manual, lista_automatica]\n",
    "    \n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis_teste = cria_lista()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...\n",
       "1    [1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis_teste2 = pd.Series(lis_teste)\n",
    "lis_teste2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√° 98 ocorrencias de relevancia = 1\n",
      "H√° 102 ocorrencias de irrelevancia = 0\n"
     ]
    }
   ],
   "source": [
    "soma_1 = 0\n",
    "soma_0 = 0\n",
    "for e in lis_teste2[1]:\n",
    "    if e == 1:\n",
    "        soma_1 += 1\n",
    "    else:\n",
    "        soma_0 += 1\n",
    "        \n",
    "print('H√° {0} ocorrencias de relevancia = 1'.format(soma_1))\n",
    "print('H√° {0} ocorrencias de irrelevancia = 0'.format(soma_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica(lis):\n",
    "    soma = 0\n",
    "    i = 0\n",
    "    for e in lis[0]:\n",
    "        if lis[0][i] == lis[1][i]:\n",
    "            soma += 1\n",
    "        i += 1\n",
    "                \n",
    "    valor = (soma/len(lis[0])) * 100\n",
    "    \n",
    "    return print('Em compara√ß√£o com a relevancia dada manuamente a relevancia dada pelo seu c√≥digo √© de {0}%'.format(valor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Em compara√ß√£o com a relevancia dada manuamente a relevancia dada pelo seu c√≥digo √© de 76.0%\n"
     ]
    }
   ],
   "source": [
    "verifica(lis_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
